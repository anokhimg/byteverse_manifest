version: 0.1.0
jobId: "1216"
jobName: test1234567
jobType: Source Aligned Data Product
alias: sadsa
discoveryPort:
  name: test123456789
inputPorts:
  - alias: weather_day_1_2
    description: weather day
    tags: []
    extra: {}
    syncType: pull
    type: s3-csv
    dataSetUrn: urn:dv:dataset:3a0494b4-86e9-430f-afcb-877a0d9bea95
    filter: ""
    projection: []
    persistDataFrame: false
    entity:
      advanceOptions:
        mergeSchema: false
  - alias: Test_DataSet_Anokhi_1
    description: Test-DataSet-Anokhi
    tags: []
    extra: {}
    syncType: pull
    type: s3-csv
    dataSetUrn: urn:dv:dataset:b7f9a3b8-d1cf-43c8-b99d-e4fe24fe097b
    filter: ""
    projection: []
    persistDataFrame: false
    entity:
      advanceOptions:
        mergeSchema: false
productState:
  stepName: sadsa
  inputDataFrame: EMR_PySpark_1
  tableName: asdas
  warehousePath: saddas
  catalogName: adasd
  writeMode: Overwrite
  stateType: inputParquet
  stateName: asdasd
  optional:
    encodingType: HASH
    persistDataFrame: false
  type: stateManagement
  sequence: 4
  updateStrategy: Overwrite
  refreshInterval: "* * * 2 2"
transformation:
  - alias: EMR_PySpark_1
    stepName: adasd
    arguments:
      - s3://byte-etl-externaldemo/weather_data/20230626110117.csv
      - s3://byte-etl-externaldemo/##weather_data##/##11##/##123##/##1234##/##dateInter##.csv
    pythonFilePath: asdasda
    inputDataFrameList:
      - inputDataFrame: weather$day$1
        tempViewName: ""
      - inputDataFrame: Test-DataSet-Anokhi$1
        tempViewName: ""
    optional:
      pythonExtraZipFilePath: asdasd
      pythonEnvTarGZPath: sasdasdas
    type: customPySparkEMRServerless
    sequence: 3
    references:
      - alias: weather_day_1
        sqlReference: ""
      - alias: Test-DataSet-Anokhi_1
        sqlReference: ""
controlPort:
  dataQualityRules: {}
outputPort:
  subscriptionChannels:
    - channelType: Postgres
      queryType: SQL
